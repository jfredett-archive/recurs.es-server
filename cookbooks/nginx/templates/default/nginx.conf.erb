worker_processes <%= node['nginx']['worker_processes'] %>;
user <%= node['nginx']['executing']['user'] %> <%= node['nginx']['executing']['group'] %>;

pid <%= node['nginx']['location']['pid'] %>;
error_log <%= node['nginx']['location']['error_log'] %>;

events {
  worker_connections <%= node['nginx']['worker_connections'] %>; # increase if you have lots of clients
  accept_mutex <%= node['nginx']['worker_connections'] > 1 ? 'on' : 'off' %>;
  use epoll;
  #if platform? *nonlinux_platforms then "kqueue" else "epoll" end ;
}

http {
  include mime.types;
  access_log <%= node['nginx']['location']['access_log'] %>;

  sendfile on;     # send static files w/ node['nginx']

  tcp_nopush on;   # off may be better for *some* Comet/long-poll stuff
  tcp_nodelay off; # on may be better for some Comet/long-poll stuff

  # we haven't checked to see if Rack::Deflate on the app server is
  # faster or not than doing compression via node['nginx'].  It's easier
  # to configure it all in one place here for static files and also
  # to disable gzip for clients who don't get gzip/deflate right.
  # There are other other gzip settings that may be needed used to deal with
  # bad clients out there, see http://wiki.node['nginx'].org/NginxHttpGzipModule
  #
  gzip on;
  gzip_http_version 1.0;
  gzip_proxied any;
  gzip_min_length 500;
  gzip_disable "MSIE [1-6]\.";
  gzip_types text/plain text/xml text/css text/comma-separated-values text/javascript application/x-javascript application/atom+xml;

  upstream app_server {
    # fail_timeout=0 means we always retry an upstream even if it failed
    # to return a good HTTP response (in case the Unicorn master nukes a
    # single worker for timing out).

    <% if node['nginx']['socket?'] %>
      # for UNIX domain socket setups:
      server unix:/tmp/<%= node['nginx']['socket_name'] %> fail_timeout=0;
    <% else %>
      # for TCP setups, point these to your backend servers
      server 127.0.0.1:<%= node['nginx']['tcp_port'] %> fail_timeout=0;
    <% end %>

  }

  server {
    server_name localhost;
    root <%= node['nginx']['location']['static_files'] %>;

   # % if platform? 'FreeBSD' %>
   #   listen 80 default deferred;
   # % else %>
      listen 80 default; # accept_filter=httpready
   # % end %>

    # If you have IPv6, you'll likely want to have two separate listeners.
    # One on IPv4 only (the default), and another on IPv6 only instead
    # of a single dual-stack listener.  A dual-stack listener will make
    # for ugly IPv4 addresses in $remote_addr (e.g ":ffff:10.0.0.1"
    # instead of just "10.0.0.1") and potentially trigger bugs in
    # some software.
    # listen [::]:80 ipv6only=on; # deferred or accept_filter recommended

    client_max_body_size <%= node['nginx']["max_body_size"] %>;
    keepalive_timeout <%= node['nginx']['keepalive'] %>;

    # Prefer to serve static files directly from node['nginx'] to avoid unnecessary
    # data copies from the application server.
    #
    # try_files directive appeared in in node['nginx'] 0.7.27 and has stabilized
    # over time.  Older versions of node['nginx'] (e.g. 0.6.x) requires
    # "if (!-f $request_filename)" which was less efficient:
    # http://bogomips.org/unicorn.git/tree/examples/node['nginx'].conf?id=v3.3.1#n127
#    try_files $uri/index.html $uri.html $uri @app <%= node['nginx']['try_files'].join(' ') %>;

   # location @app {
   #   # an HTTP header important enough to have its own Wikipedia entry:
   #   #   http://en.wikipedia.org/wiki/X-Forwarded-For
   #   proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

   #   # enable this if and only if you use HTTPS, this helps Rack
   #   # set the proper protocol for doing redirects:
   #   # proxy_set_header X-Forwarded-Proto https;

   #   # pass the Host: header from the client right along so redirects
   #   # can be set properly within the Rack application
   #   proxy_set_header Host $http_host;

   #   # we don't want node['nginx'] trying to do something clever with
   #   # redirects, we set the Host: header above already.
   #   proxy_redirect off;

   #   # set "proxy_buffering off" *only* for Rainbows! when doing
   #   # Comet/long-poll/streaming.  It's also safe to set if you're using
   #   # only serving fast clients with Unicorn + node['nginx'], but not slow
   #   # clients.  You normally want node['nginx'] to buffer responses to slow
   #   # clients, even with Rails 3.1 streaming because otherwise a slow
   #   # client can become a bottleneck of Unicorn.
   #   #
   #   # The Rack application may also set "X-Accel-Buffering (yes|no)"
   #   # in the response headers do disable/enable buffering on a
   #   # per-response basis.
   #   # proxy_buffering off;

   #   proxy_pass http://app_server;
   # }

    # Rails error pages
    error_page 500 502 503 504 /500.html;
    location = /500.html {
      root <%= node['nginx']['location']['error_pages'] %> 
    }
  }
}
